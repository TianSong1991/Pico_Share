{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>朴素贝叶斯</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Author： TianSong</font>\n",
    "\n",
    "<font size=5>Date: 20180927</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯（Naïve Bayes）属于监督学习的生成模型，实现简单，没有迭代，学习效率高，在大样本量下会有较好的表现。但因为假设太强——<font color=\"red\">假设特征条件独立</font>，在输入向量的特征条件有关联的场景下并不适用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯为什么是“朴素”的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯算法是基于贝叶斯定理与特征条件独立假设的分类方法，朴素贝叶斯之所以有朴素两个字，就是因为它把问题简化了，假设所有特征参数均相互独立。比如，如果水果呈红色，圆形，直径约3英寸，则可认为它是苹果。 即使这些特征依赖于彼此或者依赖于其他特征的存在，所有这些特征独立地贡献了这种水果是苹果的可能性，这就是为什么它被称为“朴素”的原因。朴素贝叶斯算法很容易构建且对大型数据库非常有用，多用于多元类别下的文本分类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用贝叶斯定理、全概率公式、条件独立性等进行运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://mmbiz.qpic.cn/mmbiz_png/LiaGhAsRNttuPk8rIHM7jGlWkooIsdMyB7mBYmOaevWzPuvjPG4YCbIy6gko6HJ1m5lSAseh42SQIXib6MCfXuYA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事件$c$发生的概率为$P(c)$，即先验概率；事件x发生的概率为$P(x)$；在事件$c$发生的条件下事件x发生的概率为$P(x|c)$；在事件$x$发生的条件下事件$c$发生的概率为$P(c|x)$，其中$P(x|c)P(c)= P(c,x)$，即事件$c$、$x$同时发生的概率。\n",
    "\n",
    "\n",
    "\n",
    "那么根据贝叶斯定律：在事件$x$发生的条件下事件$c$发生的概率为$P(c|x)$，即后验概率，等于在事件$x$发生的条件下事件$c$、$x$同时发生的概率。\n",
    "\n",
    "\n",
    "\n",
    "而朴素贝叶斯算法则针对多元分类问题，假设在事件$x_1、x_2…x_n$均发生条件下事件c的概率，这里假设$x_1、x_2…x_n$相互独立，那么$P(x|c)$的概率就可以计算为：$P(x|c)= P(x_1|c) P(x_2|c)* … *P(x_n|c)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类器的主要思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过联合概率$P(x,y)=P(x|y)P(y)$建模，运用贝叶斯定理求解后验概率$P(y|x)$,将后验概率最大者对应的的类别作为预测类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们定义训练集$T = \\{(x_1,y_1),(x_2,y_2),(x_3,y_3),...,(x_n,y_n)\\}$，其类别$y_i \\in \\{c_1,c_2,...,c_k\\}$，则训练集中样本点数为$n$，类别数为$k$。\n",
    "\n",
    "输入待预测数据$X$，则预测类别\n",
    "\n",
    "$$arg \\max \\limits_{c_{k}}p(y=c_k|x) \\qquad \\qquad    (1)$$\n",
    "\n",
    "由贝叶斯定理可知：\n",
    "\n",
    "$$p(y=c_k|x)=\\frac{p(x|y=c_k)p(y=c_k)}{p(x)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于类别$c_{k}$而言，$p(x)$是恒等的，因此式子$(1)$等价于\n",
    "\n",
    "$$arg \\max \\limits_{c_k}p(x|y=c_k)p(y=c_k) \\qquad  \\qquad (2)$$\n",
    "\n",
    "从上面式子可以看出：朴素贝叶斯将分类问题转化成了求条件概率与先验概率的最大乘积问题。先验概率$p(y=c_{k})$可通过计算类别的频率得到，但如何计算条件概率$p(x|y=c_{k})$呢？\n",
    "\n",
    "朴素贝叶斯对条件概率做了条件独立性的假设，即特征条件相互独立。设输入$X$为$n$维特征向量$(x^{(1)},x^{(2)},...,x^{(j)},...,x^{(n)})$，第$j$ 维特征$x^{(j)}$的取值有$S_{j}$个。由概率论的知识可知：\n",
    "\n",
    "$$p(x|y=c_k)=\\prod\\limits_jp(x^{(j)}|y=c_k)$$\n",
    "\n",
    "式子$(2)$等价于\n",
    "\n",
    "$$arg \\max \\limits_{c_k}p(y=c_k)\\prod\\limits_{j}p(x^{(j)}|y=c_k) \\qquad \\qquad (3)$$\n",
    "\n",
    "为什么要选择后验概率最大的类别作为预测类别呢？因为后验概率最大化，可以使得期望风险最小化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 极大似然估计\n",
    "\n",
    "在朴素贝叶斯学习中，需要估计先验概率与条件概率，一般时采用极大似然估计。先验概率的极大似然估计：\n",
    "\n",
    "$$\\hat{p}(y=c_k)=\\frac{\\sum_{i}I(y_i=c_k)}{N}$$\n",
    "\n",
    "其中，$I$是指示函数，满足括号内条件时为$1$否则为$0$；可以看作为计数。\n",
    "\n",
    "设第$j$维特征的取值空间为$\\{a_{j1},a_{j2},...,a_{jS}\\}$，且输入变量的第$j$维$x^{(j)}=a_{jl}$，则条件概率的极大似然估计：\n",
    "\n",
    "$$\\hat{p}(x^{(j)}=a_{jl}|y=c_k)=\\frac{\\sum\\limits_{i}I(x_{i}^{(j)}=a_{jl},y=c_k)}{I(y_i=c_k)}$$\n",
    "\n",
    "###  贝叶斯估计\n",
    "\n",
    "在估计先验概率与条件概率时，有可能出现为$0$的情况，则计算得到的后验概率亦为$0$，从而影响分类的效果。因此，需要在估计时做平滑，这种方法被称为贝叶斯估计$（Bayesian estimation）$。先验概率的贝叶斯估计：\n",
    "\n",
    "$$\\hat{p}(y=c_k)=\\frac{\\sum_{i}I(y_i=c_k)+\\lambda}{N+k\\lambda}$$\n",
    "\n",
    "后验概率的贝叶斯估计：\n",
    "\n",
    "$$\\hat{p}(x^{(j)}=a_{jl}|y=c_k)=\\frac{\\sum\\limits_{i}I(x_{i}^{(j)}=a_{jl},y=c_k)+\\lambda}{I(y_i=c_k)+S_{j}\\lambda}$$\n",
    "\n",
    "常取$\\lambda = 1$，这时被称为$Laplace$平滑$（Laplace smoothing）$。下面提到的拼写检查则用到了$Laplace$平滑——初始时将所有单词的计数置为$1$。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯的优缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优点：\n",
    "（1）对数据的预测是简单、快捷和高效的，特别在多元分类任务；<br>（2）当特征相互独立的假设成立，其预测能力好于逻辑回归等其他算法，适合增量式训练，尤其是数据量超出内存时，我们可以一批批的去增量训练。<br>（3）相比于输入变量为数值变量时，它在分类变量的情况下表现良好，若是数值变量，则需要假设其为正态分布。\n",
    "\n",
    "### 缺点：\n",
    "（1）朴素贝叶斯算法的假设条件在实际中往往很难成立，在属性个数比较多或者属性之间相关性较大时，分类效果不好。<br>（2）需要知道先验概率，且先验概率很多时候取决于假设，假设的模型可以有很多种，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳。<br>（3）对输入数据的表达形式很敏感"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯的应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）实时预测：朴素贝叶斯算法简单便捷。 因此，它可以用于实时进行预测。\n",
    "\n",
    "（2）多分类预测：适用于目标变量为多类别的任务，这里我们可以预测多类目标变量的概率。\n",
    "\n",
    "（3）文本分类/垃圾邮件过滤/情感分析：主要用于文本分类的朴素贝叶斯分类器（由于多类问题和独立规则更好的结果）与其他算法相比具有更高的成功率。 因此，它被广泛用于垃圾邮件过滤（识别垃圾邮件）和情感分析（在社交媒体分析中，识别积极和消极的客户情绪）\n",
    "\n",
    "（4）推荐系统：朴素贝叶斯分类器和协作过滤一起构建推荐系统，该系统使用机器学习和数据挖掘技术来过滤看不见的信息并预测用户是否会喜欢给定的资源，简单的例子就是淘宝上的商品推荐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯的python简单实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在python的scikit learn库中有朴素贝叶斯的程序包，它包括三种类型：\n",
    "\n",
    "（1）高斯Gaussian：用于分类，它假定特征遵循正态分布。\n",
    "\n",
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$\n",
    "\n",
    "（2）多项Multinomial：用于离散计数。例如，假设我们有文本分类问题。在这里，我们可以考虑更进一步的伯努利试验，而不是“在文档中出现的词”，而是“计算文档中出现词的频率”，您可以将其视为“在$n$次试验中观察结果数$x_i$出现的次数”。\n",
    "\n",
    "$$\\hat{\\theta}_{yi} = \\frac{ N_{yi} + \\alpha}{N_y + \\alpha n}$$\n",
    "\n",
    "(3)补充Complement：实现补充朴素贝叶斯（CNB）算法。CNB是标准多项式朴素贝叶斯（MNB）算法的改编，其特别适用于不平衡数据集。具体而言，CNB使用来自每个类的补集的统计来计算模型的权重。CNB的发明人凭经验证明，CNB的参数估计比MNB的参数估计更稳定。此外，CNB在文本分类任务上的表现通常优于MNB（通常相当大）。\n",
    "\n",
    "$$\\begin{align}\\begin{aligned}\\hat{\\theta}_{ci} = \\frac{\\alpha_i + \\sum_{j:y_j \\neq c} d_{ij}}\n",
    "                         {\\alpha + \\sum_{j:y_j \\neq c} \\sum_{k} d_{kj}}\\\\w_{ci} = \\log \\hat{\\theta}_{ci}\\\\w_{ci} = \\frac{w_{ci}}{\\sum_{j} |w_{cj}|}\\end{aligned}\\end{align}$$\n",
    "\n",
    "（3）伯努利Bernoulli：如果你的特征向量是0-1分类，二项模型很有用。比如在文本分类，其中“1、0”分别是“词语出现在文档中”和“词语文档不出现在文档中”。\n",
    "\n",
    "$$P(x_i \\mid y) = P(i \\mid y) x_i + (1 - P(i \\mid y)) (1 - x_i)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面以高斯模型为例，其Python代码为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import Library of Gaussian Naive Bayes modelfrom sklearn.naive_bayes import GaussianNBimport numpy as np#假设存在这样的二元特征变量x，对应属性Y\n",
    "x= np.array([[-3,7],[1,5], [1,2], [-2,0], [2,3], [-4,0], [-1,1], [1,1], [-2,2], [2,7], [-4,1], [-2,7]])\n",
    "Y = np.array([3, 3, 4, 4, 4, 3, 3, 4, 3, 3, 3, 4])\n",
    "id3 = np.where(Y==3)\n",
    "id4 = np.where(Y==4)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.scatter(x[id3,0], x[id3,1],s=50, c='b', marker='o', label='Y=3')\n",
    "ax.scatter(x[id4,0], x[id4,1], s=50, c='r', marker='x', label='Y=4')\n",
    "ax.legend()\n",
    "ax.set_xlabel('X[:,0]')\n",
    "ax.set_ylabel('X[:,1]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图可以看到，我们构造的$x$二元特征变量，在不同Y类别下的散点图分布情况，基本可以看到$Y=3$与$Y=4$两类$x$有一定的线性可分性。\n",
    "\n",
    "\n",
    "\n",
    "接下来就用高斯分布的朴素贝叶斯去训练该数据集，并对$[1,2]$,$[3,7]$两个测试数据进行类别预测，结果与$Logistic$回归的预测结果进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model.logistic import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "# Train the model using the training sets \n",
    "model.fit(x, Y)\n",
    "#Predict Output \n",
    "predicted= model.predict([[1,2],[3,7]])\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression Predict \n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(x, Y)\n",
    "predictions=classifier.predict([[1,2],[3,7]])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出结果，朴素贝叶斯结果为$array([4, 3])$，也就是特征变量$[1,2]$,$[3,7]$对应Y取值分别为$4$,$3$；而Logistic回归的预测结果$array([4, 4])$，即两个特征变量的Y取值均为$4$.\n",
    "\n",
    "由于数据来自我们构造的无法去判断测试集预测结果的准确性，但是我们可以将特征变量$[1,2]$,$[3,7]$放到前边x的分类散点图坐标体系中，初步可以看到朴素贝叶斯的预测相对比较准确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
